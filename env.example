# Code Server Configuration
CODE_SERVER_PASSWORD=devstack123

# GitHub Integration
GITHUB_TOKEN=your_github_personal_access_token_here

# GitLab Integration
GITLAB_TOKEN=your_gitlab_personal_access_token_here
GITLAB_URL=https://gitlab.com

# Ollama Configuration
# Ollama runs natively on the Docker host (not in a container)
# Ensure Ollama is installed and running on the host, listening on 0.0.0.0:11434
# For containers to access host Ollama, use host.docker.internal:11434
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_URL=http://host.docker.internal:11434

# Recommended Models (for NVIDIA RTX PRO 6000 Blackwell 96GB VRAM)
# Coding Models
OLLAMA_CODING_MODEL=deepseek-coder:33b
# Reasoning Models  
OLLAMA_REASONING_MODEL=qwen2.5:72b
# Embedding Models
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Agent Configuration
AGENT_TEMPERATURE=0.7
AGENT_MAX_TOKENS=8192

# Rules Engine
RULES_PATH=./rules

